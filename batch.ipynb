{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing author: Claudio Brunstein\n",
      "Processing author: Alireza Navadeh\n",
      "Processing author: Anita Reddy\n",
      "Processing author: Kamonpun Ussavarungsi\n",
      "Processing author: Neha Solanki\n",
      "Processing author: Matthew Dettmer\n",
      "Processing author: Emily Pennington\n",
      "Processing author: Sudhir Krishnan\n",
      "Processing author: Matthew Siuba\n",
      "Processing author: Umur Hatipoglu\n",
      "Processing author: Wayne Tsuang\n",
      "Processing author: Jorge Ataucuri-Vargas\n",
      "Processing author: Loutfi Aboussouan\n",
      "Processing author: Peter Mazzone\n",
      "Processing author: Francisco Almeida\n",
      "Processing author: Sameep Sehgal\n",
      "Processing author: Margaret Kuder\n",
      "Processing author: Bo Xu\n",
      "Processing author: Jona Banzon\n",
      "Processing author: James Fernandez\n",
      "Processing author: Donald Dumford III\n",
      "Processing author: Nabin Shrestha\n",
      "Processing author: Ken Wong\n",
      "Processing author: Eduardo Mireles-Cabodevila\n",
      "Processing author: Deepakraj Gajanana\n",
      "Processing author: Stephen Ellis\n",
      "Processing author: Ajit Moghekar\n",
      "Processing author: Oussama Wazni\n",
      "Processing author: Jessica Lovich-Sapola\n",
      "Processing author: Milind Desai\n",
      "Processing author: Ihab Riad\n",
      "Processing author: Christine Koval\n",
      "Processing author: Peng Zhang\n",
      "Processing author: Peng Qi\n",
      "Processing author: Brian Hill\n",
      "Processing author: Jacob Miller\n",
      "Processing author: Ping Xia\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from Bio import Entrez\n",
    "from Bio import Medline\n",
    "from collections import defaultdict\n",
    "from datetime import datetime\n",
    "import re\n",
    "import http.client  # for catching IncompleteRead\n",
    "from http.client import IncompleteRead\n",
    "\n",
    "def parse_author_name(author_name):\n",
    "    \"\"\"\n",
    "    Given an author name like 'Smith, John', returns (last, initials).\n",
    "    Or if the name is 'John Smith', also returns (last, initials).\n",
    "    \"\"\"\n",
    "    if ',' in author_name:\n",
    "        last, first = author_name.split(',', 1)\n",
    "        last = last.strip()\n",
    "        first = first.strip()\n",
    "        initials = ''.join([part[0] for part in first.split() if part])\n",
    "    else:\n",
    "        parts = author_name.split()\n",
    "        if len(parts) == 1:\n",
    "            last = parts[0]\n",
    "            initials = \"\"\n",
    "        else:\n",
    "            last = parts[-1]\n",
    "            first_parts = parts[:-1]\n",
    "            initials = ''.join([p[0] for p in first_parts])\n",
    "    return last, initials\n",
    "\n",
    "def match_author(record_author, target_last, target_initials):\n",
    "    parts = record_author.split()\n",
    "    if len(parts) < 2:\n",
    "        return False\n",
    "    last_name = parts[0]\n",
    "    initials = \"\".join(parts[1:])\n",
    "    return (\n",
    "        last_name.lower() == target_last.lower()\n",
    "        and initials.lower().startswith(target_initials.lower())\n",
    "    )\n",
    "\n",
    "def get_pubmed_ids_for_author(author_name, email):\n",
    "    \"\"\"\n",
    "    Return a list of PubMed IDs for a given author name.\n",
    "    \"\"\"\n",
    "    Entrez.email = email or \"your_email@example.com\"\n",
    "    \n",
    "    target_last, target_initials = parse_author_name(author_name)\n",
    "    if target_initials:\n",
    "        query = f'{target_last} {target_initials}[Author]'\n",
    "    else:\n",
    "        query = f'{target_last}[Author]'\n",
    "\n",
    "    handle = Entrez.esearch(db=\"pubmed\", term=query, retmax=100000)\n",
    "    record = Entrez.read(handle)\n",
    "    handle.close()\n",
    "    pmid_list = record.get(\"IdList\", [])\n",
    "    return pmid_list, target_last, target_initials\n",
    "\n",
    "def get_author_positions_by_year(pmid_list, target_last, target_initials, email, hire_date=None):\n",
    "    \"\"\"\n",
    "    For each PubMed ID, fetch the MEDLINE record and determine whether the target author is\n",
    "    first, middle, or last. Only include papers published AFTER the given hire_date (if provided).\n",
    "    Return a dict of { year : {\"first\": count, \"middle\": count, \"last\": count} }.\n",
    "    \"\"\"\n",
    "    Entrez.email = email or \"your_email@example.com\"\n",
    "    \n",
    "    year_data = defaultdict(lambda: {\"first\": 0, \"middle\": 0, \"last\": 0})\n",
    "    BATCH_SIZE = 200\n",
    "\n",
    "    for start in range(0, len(pmid_list), BATCH_SIZE):\n",
    "        batch = pmid_list[start:start+BATCH_SIZE]\n",
    "        try:\n",
    "            handle = Entrez.efetch(db=\"pubmed\", id=batch, rettype=\"medline\", retmode=\"text\")\n",
    "            records = Medline.parse(handle)\n",
    "\n",
    "            for record in records:\n",
    "                if 'AU' not in record:\n",
    "                    continue\n",
    "                authors = record['AU']\n",
    "                \n",
    "                # Attempt to parse the publication date\n",
    "                dp = record.get('DP', '')  # e.g. '2022 Dec', '2022', '2022 Jul 1'\n",
    "                pub_date = None\n",
    "                try:\n",
    "                    # Try to parse the entire date with pandas\n",
    "                    pub_date = pd.to_datetime(dp, errors='coerce')\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "                # If parsing failed or returned NaT, fallback to year-based approach\n",
    "                if pub_date is None or pd.isnull(pub_date):\n",
    "                    # If dp is at least 4 chars and the first 4 are digits, treat that as the year\n",
    "                    if len(dp) >= 4 and dp[:4].isdigit():\n",
    "                        try:\n",
    "                            year_only = int(dp[:4])\n",
    "                            # Approximate it to Jan 1 of that year\n",
    "                            pub_date = datetime(year_only, 1, 1)\n",
    "                        except:\n",
    "                            # Could not parse year, skip\n",
    "                            continue\n",
    "                    else:\n",
    "                        # Could not parse DP in any useful way\n",
    "                        continue\n",
    "\n",
    "                # If we have a hire_date, skip publications published on or before the hire_date\n",
    "                if hire_date is not None and pub_date <= hire_date:\n",
    "                    continue\n",
    "\n",
    "                pub_year = str(pub_date.year)  # Weâ€™ll store the counts under the year\n",
    "\n",
    "                # Find all positions of the target author in the author list\n",
    "                found_positions = [\n",
    "                    i for i, a in enumerate(authors) \n",
    "                    if match_author(a, target_last, target_initials)\n",
    "                ]\n",
    "                for pos in found_positions:\n",
    "                    if pos == 0:\n",
    "                        year_data[pub_year][\"first\"] += 1\n",
    "                    elif pos == len(authors) - 1:\n",
    "                        year_data[pub_year][\"last\"] += 1\n",
    "                    else:\n",
    "                        year_data[pub_year][\"middle\"] += 1\n",
    "        finally:\n",
    "            # Always close the handle, even if there's an exception\n",
    "            handle.close()\n",
    "\n",
    "    return year_data\n",
    "\n",
    "def get_year_metrics(author_name, email, hire_date=None):\n",
    "    \"\"\"\n",
    "    Wrapper function to return a dictionary of year-based metrics\n",
    "    {year: {\"first\", \"middle\", \"last\", \"total\", \"first_fraction\", \"last_fraction\"}}\n",
    "    Only includes papers after the given hire_date if provided.\n",
    "    \"\"\"\n",
    "    pmid_list, target_last, target_initials = get_pubmed_ids_for_author(author_name, email)\n",
    "    year_data = get_author_positions_by_year(\n",
    "        pmid_list, target_last, target_initials, email, hire_date=hire_date\n",
    "    )\n",
    "    \n",
    "    results = {}\n",
    "    for year, data in year_data.items():\n",
    "        total = data[\"first\"] + data[\"middle\"] + data[\"last\"]\n",
    "        first_fraction = round(data['first']/total, 2) if total else 0\n",
    "        last_fraction = round(data['last']/total, 2) if total else 0\n",
    "        results[year] = {\n",
    "            \"first\": data[\"first\"],\n",
    "            \"middle\": data[\"middle\"],\n",
    "            \"last\": data[\"last\"],\n",
    "            \"total\": total,\n",
    "            \"first_fraction\": first_fraction,\n",
    "            \"last_fraction\": last_fraction\n",
    "        }\n",
    "    return results\n",
    "\n",
    "def main():\n",
    "    input_file = \"input.xlsx\"   # Change to your actual input file path\n",
    "    output_file = \"output.xlsx\" # Change to desired output path\n",
    "    \n",
    "    df = pd.read_excel(input_file)\n",
    "    \n",
    "    all_years = set()\n",
    "    result_rows = []\n",
    "    skipped_authors = []\n",
    "    processed_authors = []\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        raw_name = str(row[\"Name\"])\n",
    "        \n",
    "        # Remove the (xxxxxx) part if present\n",
    "        name_cleaned = re.sub(r\"\\(\\d+\\)\", \"\", raw_name).strip()\n",
    "        \n",
    "        print(f\"Processing author: {name_cleaned}\")\n",
    "        \n",
    "        email = row.get(\"Email\", \"your_email@example.com\")\n",
    "        \n",
    "        # ---- Parse the hire date (if available) into a datetime ----\n",
    "        hire_date_value = row.get(\"Hire Date\", None)\n",
    "        if pd.notnull(hire_date_value):\n",
    "            # Attempt to convert to datetime\n",
    "            hire_date = pd.to_datetime(hire_date_value, errors='coerce')\n",
    "        else:\n",
    "            hire_date = None\n",
    "\n",
    "        # Try/Except block to catch errors (like IncompleteRead) and skip problematic authors\n",
    "        try:\n",
    "            # Retrieve the publication metrics (only after hire_date)\n",
    "            metrics_dict = get_year_metrics(name_cleaned, email, hire_date=hire_date)\n",
    "\n",
    "            # Build a dictionary that stores the row's original data + new year columns\n",
    "            row_data = row.to_dict()\n",
    "            \n",
    "            for year, info in metrics_dict.items():\n",
    "                row_data[f\"{year}-first\"] = info[\"first\"]\n",
    "                row_data[f\"{year}-middle\"] = info[\"middle\"]\n",
    "                row_data[f\"{year}-last\"] = info[\"last\"]\n",
    "                row_data[f\"{year}-fraction_first\"] = info[\"first_fraction\"]\n",
    "                row_data[f\"{year}-fraction_last\"] = info[\"last_fraction\"]\n",
    "                row_data[f\"{year}-total\"] = info[\"total\"]\n",
    "                all_years.add(year)\n",
    "            \n",
    "            result_rows.append(row_data)\n",
    "            processed_authors.append(name_cleaned)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing author '{name_cleaned}': {e}\")\n",
    "            print(\"Skipping this author...\")\n",
    "            skipped_authors.append(name_cleaned)\n",
    "            # Continue to the next author\n",
    "            continue\n",
    "    \n",
    "    new_df = pd.DataFrame(result_rows)\n",
    "    new_df.to_excel(output_file, index=False)\n",
    "    print(f\"\\nOutput written to {output_file}\")\n",
    "\n",
    "    # Print a final summary\n",
    "    print(\"\\nFinal Summary:\")\n",
    "    print(f\"Processed authors: {processed_authors}\")\n",
    "    print(f\"Skipped authors due to errors: {skipped_authors}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
